{
  "success": true,
  "data": {
    "id": 25065,
    "name": "<p>请讲解Lora的原理</p>",
    "options": null,
    "answer": "<p>LoRA（Low-Rank Adaptation of Large Language Models）是一种高效的大模型参数微调方法，其核心原理是通过低秩分解来减少可训练参数的数量，从而在微调过程中显著降低计算成本和存储需求，同时保持与全量参数微调相近的性能。以下从几个关键方面详细讲解其原理：</p>\n<h3>核心思想</h3>\n<p>在大语言模型中，全量参数微调需要更新模型的所有参数，这不仅计算量大，还需要大量的显存。LoRA的核心思想是在不改变预训练模型原有参数的基础上，通过引入额外的可训练低秩矩阵来对模型进行微调。在推理时，将预训练模型的参数与低秩矩阵的贡献相加，得到最终的模型参数。</p>\n<h3>具体实现</h3>\n<h4>线性层的修改</h4>\n<p>\n  在神经网络中，线性层是常见的组件，其计算可以表示为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>y</mi>\n          <mo>=</mo>\n          <mi>W</mi>\n          <mi>x</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">y = Wx</annotation>\n      </semantics>\n    </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 是权重矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>x</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">x</annotation>\n      </semantics>\n    </math></span> 是输入向量，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>y</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">y</annotation>\n      </semantics>\n    </math></span> 是输出向量。在LoRA中，对线性层的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 进行修改，引入两个低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span>，使得新的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msup>\n            <mi>W</mi>\n            <mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo>\n          </msup>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W'</annotation>\n      </semantics>\n    </math></span> 为：\n  <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msup>\n            <mi>W</mi>\n            <mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo>\n          </msup>\n          <mo>=</mo>\n          <mi>W</mi>\n          <mo>+</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W' = W + BA</annotation>\n      </semantics>\n    </math></span>\n  其中，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 是预训练模型的原始权重矩阵，保持固定不参与训练；<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 是可训练的低秩矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 的形状为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n          <mo>×</mo>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>i</mi>\n              <mi>n</mi>\n            </mrow>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r \\times d_{in}</annotation>\n      </semantics>\n    </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的形状为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>o</mi>\n              <mi>u</mi>\n              <mi>t</mi>\n            </mrow>\n          </msub>\n          <mo>×</mo>\n          <mi>r</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{out} \\times r</annotation>\n      </semantics>\n    </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r</annotation>\n      </semantics>\n    </math></span> 是低秩矩阵的秩，通常远小于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>i</mi>\n              <mi>n</mi>\n            </mrow>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{in}</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>o</mi>\n              <mi>u</mi>\n              <mi>t</mi>\n            </mrow>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{out}</annotation>\n      </semantics>\n    </math></span>。\n</p>\n<h4>前向传播过程</h4>\n<p>在进行前向传播时，输入向量 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>x</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">x</annotation>\n      </semantics>\n    </math></span> 首先通过原始的线性层 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 得到 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>y</mi>\n            <mn>1</mn>\n          </msub>\n          <mo>=</mo>\n          <mi>W</mi>\n          <mi>x</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">y_1 = Wx</annotation>\n      </semantics>\n    </math></span>，然后通过低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 得到 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>y</mi>\n            <mn>2</mn>\n          </msub>\n          <mo>=</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n          <mi>x</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">y_2 = BAx</annotation>\n      </semantics>\n    </math></span>，最终的输出为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>y</mi>\n          <mo>=</mo>\n          <msub>\n            <mi>y</mi>\n            <mn>1</mn>\n          </msub>\n          <mo>+</mo>\n          <msub>\n            <mi>y</mi>\n            <mn>2</mn>\n          </msub>\n          <mo>=</mo>\n          <mi>W</mi>\n          <mi>x</mi>\n          <mo>+</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n          <mi>x</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">y = y_1 + y_2 = Wx + BAx</annotation>\n      </semantics>\n    </math></span>。</p>\n<h3>低秩分解的作用</h3>\n<p>低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的引入是LoRA的关键。由于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r</annotation>\n      </semantics>\n    </math></span> 通常远小于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>i</mi>\n              <mi>n</mi>\n            </mrow>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{in}</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>o</mi>\n              <mi>u</mi>\n              <mi>t</mi>\n            </mrow>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{out}</annotation>\n      </semantics>\n    </math></span>，低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的参数数量远小于原始权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 的参数数量。例如，假设 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>i</mi>\n              <mi>n</mi>\n            </mrow>\n          </msub>\n          <mo>=</mo>\n          <mn>768</mn>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{in} = 768</annotation>\n      </semantics>\n    </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>d</mi>\n            <mrow>\n              <mi>o</mi>\n              <mi>u</mi>\n              <mi>t</mi>\n            </mrow>\n          </msub>\n          <mo>=</mo>\n          <mn>768</mn>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">d_{out} = 768</annotation>\n      </semantics>\n    </math></span>，如果 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n          <mo>=</mo>\n          <mn>8</mn>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r = 8</annotation>\n      </semantics>\n    </math></span>，那么 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的参数数量为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mn>768</mn>\n          <mo>×</mo>\n          <mn>8</mn>\n          <mo>+</mo>\n          <mn>8</mn>\n          <mo>×</mo>\n          <mn>768</mn>\n          <mo>=</mo>\n          <mn>12288</mn>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">768 \\times 8 + 8 \\times 768 = 12288</annotation>\n      </semantics>\n    </math></span>，而原始权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 的参数数量为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mn>768</mn>\n          <mo>×</mo>\n          <mn>768</mn>\n          <mo>=</mo>\n          <mn>589824</mn>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">768 \\times 768 = 589824</annotation>\n      </semantics>\n    </math></span>，参数数量大幅减少。</p>\n<h3>训练过程</h3>\n<p>在训练过程中，只需要更新低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的参数，而预训练模型的原始权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 保持不变。这样可以显著减少需要训练的参数数量，降低计算成本和存储需求。同时，由于低秩矩阵的引入，模型仍然能够学习到任务相关的信息，从而在微调任务中取得较好的性能。</p>\n<h3>推理过程</h3>\n<p>在推理时，将低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的乘积 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">BA</annotation>\n      </semantics>\n    </math></span> 加到原始权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W</annotation>\n      </semantics>\n    </math></span> 上，得到最终的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msup>\n            <mi>W</mi>\n            <mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo>\n          </msup>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W'</annotation>\n      </semantics>\n    </math></span>。然后使用 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msup>\n            <mi>W</mi>\n            <mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo>\n          </msup>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W'</annotation>\n      </semantics>\n    </math></span> 进行前向传播，得到模型的输出。由于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msup>\n            <mi>W</mi>\n            <mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo>\n          </msup>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W'</annotation>\n      </semantics>\n    </math></span> 是一个完整的权重矩阵，推理过程与原始模型相同，不需要额外的计算开销。</p>\n<h3>优点</h3>\n<ul>\n  <li><strong>高效性</strong>：显著减少了可训练参数的数量，降低了计算成本和存储需求，使得在有限的计算资源下也能进行大模型的微调。</li>\n  <li><strong>灵活性</strong>：可以在不改变预训练模型的基础上进行微调，方便在不同的任务和数据集上进行实验。</li>\n  <li><strong>性能接近全量微调</strong>：在多个自然语言处理任务中，LoRA的性能与全量参数微调相近，能够有效地捕捉任务相关的信息。</li>\n</ul>",
    "type": 6,
    "level": 2,
    "freq": 0.007893643,
    "analysis": "<h3>1. 题目核心</h3>\n<ul>\n  <li><strong>问题</strong>：讲解Lora（Low-Rank Adaptation）的原理。</li>\n  <li><strong>考察点</strong>：\n    <ul>\n      <li>对Lora基本概念的理解。</li>\n      <li>Lora在模型微调中的作用机制。</li>\n      <li>Lora与传统模型微调方法的差异。</li>\n      <li>Lora低秩分解的原理。</li>\n    </ul>\n  </li>\n</ul>\n<h3>2. 背景知识</h3>\n<h4>（1）传统模型微调方法的问题</h4>\n<p>在大模型微调时，传统方法通常需要更新模型的所有参数。这会带来巨大的计算成本和存储需求，尤其是对于大规模预训练模型，如GPT系列等。而且在多任务场景下，为每个任务保存完整的微调后模型参数会占用大量存储空间。</p>\n<h4>（2）低秩矩阵的概念</h4>\n<p>低秩矩阵是指矩阵的秩远小于其行数和列数。低秩矩阵可以用较少的参数来近似表示，从而减少存储和计算量。</p>\n<h3>3. 解析</h3>\n<h4>（1）Lora的基本思想</h4>\n<p>Lora的核心思想是在不改变预训练模型原有参数的基础上，通过引入额外的可训练的低秩矩阵来对模型进行微调。具体来说，对于预训练模型中的某个权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span>，在微调时不直接更新它，而是引入两个低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span>，通过它们的乘积来对 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 进行修正。</p>\n<h4>（2）低秩分解的原理</h4>\n<p>假设预训练模型中的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 是一个 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>m</mi>\n          <mo>×</mo>\n          <mi>n</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">m\\times n</annotation>\n      </semantics>\n    </math></span> 的矩阵。Lora将其分解为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n          <mo>=</mo>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n          <mo>+</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W = W_0 + BA</annotation>\n      </semantics>\n    </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 是一个 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>n</mi>\n          <mo>×</mo>\n          <mi>r</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">n\\times r</annotation>\n      </semantics>\n    </math></span> 的矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 是一个 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n          <mo>×</mo>\n          <mi>m</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r\\times m</annotation>\n      </semantics>\n    </math></span> 的矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r</annotation>\n      </semantics>\n    </math></span> 是一个远小于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>m</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">m</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>n</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">n</annotation>\n      </semantics>\n    </math></span> 的秩。这样，原本需要更新 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>m</mi>\n          <mo>×</mo>\n          <mi>n</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">m\\times n</annotation>\n      </semantics>\n    </math></span> 个参数，现在只需要更新 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n          <mo stretchy=\"false\">(</mo>\n          <mi>m</mi>\n          <mo>+</mo>\n          <mi>n</mi>\n          <mo stretchy=\"false\">)</mo>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r(m + n)</annotation>\n      </semantics>\n    </math></span> 个参数，大大减少了可训练参数的数量。</p>\n<h4>（3）训练过程</h4>\n<p>在训练时，固定预训练模型的参数 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span>，只对低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 进行训练。输入数据经过预训练模型的原始权重 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 得到一部分输出，同时经过低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的乘积得到另一部分输出，将这两部分输出相加作为最终的输出。通过反向传播算法，更新 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 的参数，使得模型在特定任务上的损失最小。</p>\n<h4>（4）推理过程</h4>\n<p>在推理时，将训练好的低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 与预训练模型的权重 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 合并，得到最终的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n          <mo>=</mo>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n          <mo>+</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W = W_0 + BA</annotation>\n      </semantics>\n    </math></span>，然后使用合并后的权重进行推理。</p>\n<h4>（5）优势</h4>\n<ul>\n  <li><strong>减少计算和存储成本</strong>：由于只需要训练和存储低秩矩阵的参数，大大减少了计算量和存储需求。</li>\n  <li><strong>快速部署</strong>：可以在不改变预训练模型的基础上，快速应用到不同的任务中。</li>\n  <li><strong>避免灾难性遗忘</strong>：因为预训练模型的参数保持不变，不会出现传统微调方法中可能出现的灾难性遗忘问题。</li>\n</ul>\n<h3>4. 示例代码（以Hugging Face的transformers库为例）</h3>\n<pre><code class=\"language-python\">from transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom peft import LoraConfig, get_peft_model\n\n# 加载预训练模型和分词器\nmodel_name = \"bert-base-uncased\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# 配置Lora\nconfig = LoraConfig(\n    r=8,  # 低秩矩阵的秩\n    lora_alpha=16,\n    target_modules=[\"query\", \"key\", \"value\"],  # 需要应用Lora的模块\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"\n)\n\n# 应用Lora到模型\nmodel = get_peft_model(model, config)\n\n# 后续可以进行训练和推理\n</code></pre>\n<h3>5. 常见误区</h3>\n<h4>（1）认为Lora会降低模型性能</h4>\n<p>\n  误区：觉得减少可训练参数会导致模型性能大幅下降。\n  纠正：实际上，在很多任务中，Lora可以在大幅减少参数的情况下，取得与全量微调相近的性能。\n</p>\n<h4>（2）不理解低秩分解的作用</h4>\n<p>\n  误区：不清楚为什么要进行低秩分解。\n  纠正：低秩分解可以用较少的参数近似表示权重矩阵的变化，从而减少计算和存储成本。\n</p>\n<h4>（3）混淆Lora与其他微调方法</h4>\n<p>\n  误区：将Lora与传统的全量微调方法或其他轻量级微调方法混淆。\n  纠正：Lora的独特之处在于引入低秩矩阵对预训练模型进行修正，且不改变预训练模型的原始参数。\n</p>\n<h3>6. 总结回答</h3>\n<p>“Lora（Low-Rank Adaptation）是一种用于大模型微调的高效方法。其原理是在不改变预训练模型原有参数的基础上，通过引入额外的可训练的低秩矩阵来对模型进行微调。</p>\n<p>具体来说，对于预训练模型中的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span>，Lora将其更新为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n          <mo>=</mo>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n          <mo>+</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W = W_0 + BA</annotation>\n      </semantics>\n    </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 是低秩矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>r</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">r</annotation>\n      </semantics>\n    </math></span> 是远小于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 行数和列数的秩。在训练时，固定 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span>，只对 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 进行训练，通过反向传播算法更新它们的参数，使模型在特定任务上的损失最小。在推理时，将 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 与 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 合并得到最终的权重矩阵。</p>\n<p>Lora的优势在于能显著减少计算和存储成本，实现快速部署，同时避免灾难性遗忘问题。不过，要注意不能认为Lora会降低模型性能，它在很多任务中能取得与全量微调相近的效果。”</p>",
    "more_ask": "<ol>\n  <li>\n    <p>\n      Lora在不同深度学习框架（如TensorFlow、PyTorch）中的实现有什么差异？\n      提示：考虑框架的特性，像张量操作、自动求导机制等对Lora实现的影响。\n    </p>\n  </li>\n  <li>\n    <p>\n      如何根据具体任务和数据集来选择Lora的秩（rank）参数？\n      提示：思考任务复杂度、数据集规模与秩参数之间的关系。\n    </p>\n  </li>\n  <li>\n    <p>\n      Lora与其他参数高效微调方法（如Adapter、Prefix Tuning）相比，在计算资源和性能上各有什么优劣？\n      提示：从内存占用、训练时间、模型效果等方面对比。\n    </p>\n  </li>\n  <li>\n    <p>\n      在使用Lora进行微调时，如何处理模型的过拟合问题？\n      提示：结合Lora的特点，考虑正则化、数据增强等方法。\n    </p>\n  </li>\n  <li>\n    <p>\n      Lora对预训练模型的架构有什么要求吗？是否适用于所有类型的预训练模型？\n      提示：分析不同架构（如CNN、Transformer）的特点对Lora应用的影响。\n    </p>\n  </li>\n  <li>\n    <p>\n      当Lora微调后的模型在新数据集上效果不佳时，你会采取哪些调试策略？\n      提示：从Lora参数调整、数据处理、模型融合等角度思考。\n    </p>\n  </li>\n  <li>\n    <p>\n      如何评估Lora微调后模型的泛化能力？\n      提示：可以考虑使用交叉验证、不同分布的测试集等方法。\n    </p>\n  </li>\n  <li>\n    <p>\n      Lora在多模态模型（如视觉 - 语言模型）中的应用有什么特殊之处？\n      提示：关注多模态数据的特点和多模态模型的结构。\n    </p>\n  </li>\n</ol>",
    "mindmap": "mindmap\n  root((LoRA（Low - Rank Adaptation of Large Language Models）))\n    核心原理\n      通过低秩分解减少可训练参数数量\n      降低计算和存储需求\n      保持与全量参数微调相近性能\n    核心思想\n      不改变预训练模型原有参数\n      引入额外可训练低秩矩阵微调\n      推理时相加得到最终参数\n    具体实现\n      线性层的修改\n        引入低秩矩阵A和B\n        新权重矩阵W' = W + BA\n      前向传播过程\n        y1 = Wx\n        y2 = BAx\n        y = y1 + y2\n    低秩分解的作用\n      低秩矩阵参数数量远小于原始矩阵\n    训练过程\n      只更新低秩矩阵A和B参数\n      原始权重矩阵W不变\n    推理过程\n      低秩矩阵乘积加到原始矩阵得W'\n      用W'前向传播\n    优点\n      高效性\n      灵活性\n      性能接近全量微调",
    "keynote": "LoRA是大模型参数微调方法\n核心原理：低秩分解减参数，降成本，保性能\n核心思想：不改原参数，引低秩矩阵，推理相加\n具体实现：线性层改权重，前向传播分两步\n低秩分解：参数数量大幅减少\n训练过程：只更新低秩矩阵参数\n推理过程：低秩乘积加原始矩阵\n优点：高效、灵活、性能接近全量微调",
    "group_id": 108,
    "kps": [
      "深度学习",
      "大模型"
    ],
    "years": [
      2025,
      2024
    ],
    "corps": [
      "奇富科技",
      "好未来",
      "百度",
      "京东",
      "长安汽车",
      "华为",
      "快手",
      "蚂蚁集团",
      "美图",
      "字节跳动",
      "腾讯",
      "美团"
    ]
  }
}