{
  "success": true,
  "data": {
    "id": 207523,
    "name": "<p>请阐述大模型微调的技术原理，如LoRA、P-tuning</p>",
    "options": null,
    "answer": "<h3>大模型微调概述</h3>\n<p>大模型微调是在预训练大模型的基础上，针对特定任务或领域数据对模型进行进一步训练，以提升模型在该特定场景下的性能。传统的全量参数微调需要更新模型的所有参数，计算资源和存储需求大。而LoRA、P - tuning等方法则是高效微调技术，能在减少计算和存储开销的同时取得较好的微调效果。</p>\n<h3>LoRA（Low - Rank Adaptation）</h3>\n<h4>原理</h4>\n<p>LoRA的核心思想是通过低秩分解来近似表示预训练模型参数的更新，从而减少需要训练的参数数量。</p>\n<ul>\n  <li><strong>低秩分解</strong>：对于预训练模型中的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W_0</annotation>\n        </semantics>\n      </math></span>（通常维度很高），在微调时不直接更新 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W_0</annotation>\n        </semantics>\n      </math></span>，而是引入两个低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">A</annotation>\n        </semantics>\n      </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">B</annotation>\n        </semantics>\n      </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">A</annotation>\n        </semantics>\n      </math></span> 的维度为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>d</mi>\n            <mo>×</mo>\n            <mi>r</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">d\\times r</annotation>\n        </semantics>\n      </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">B</annotation>\n        </semantics>\n      </math></span> 的维度为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>r</mi>\n            <mo>×</mo>\n            <mi>d</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">r\\times d</annotation>\n        </semantics>\n      </math></span>（<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>r</mi>\n            <mo>≪</mo>\n            <mi>d</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">r\\ll d</annotation>\n        </semantics>\n      </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>r</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">r</annotation>\n        </semantics>\n      </math></span> 是低秩矩阵的秩）。微调过程中，只训练 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">A</annotation>\n        </semantics>\n      </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">B</annotation>\n        </semantics>\n      </math></span> 这两个矩阵，而 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W_0</annotation>\n        </semantics>\n      </math></span> 保持不变。</li>\n  <li><strong>权重更新</strong>：微调后的权重矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>W</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W</annotation>\n        </semantics>\n      </math></span> 表示为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>W</mi>\n            <mo>=</mo>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n            <mo>+</mo>\n            <mi>α</mi>\n            <mi>B</mi>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W = W_0+\\alpha BA</annotation>\n        </semantics>\n      </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>α</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">\\alpha</annotation>\n        </semantics>\n      </math></span> 是一个缩放因子，用于调整低秩矩阵对权重更新的影响程度。在推理阶段，将 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">BA</annotation>\n        </semantics>\n      </math></span> 与 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W_0</annotation>\n        </semantics>\n      </math></span> 相加得到最终的权重矩阵，这样就可以像使用普通微调后的模型一样进行推理。</li>\n</ul>\n<h4>优势</h4>\n<ul>\n  <li><strong>减少训练参数</strong>：由于只训练低秩矩阵 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">A</annotation>\n        </semantics>\n      </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">B</annotation>\n        </semantics>\n      </math></span>，大大减少了需要训练的参数数量，降低了计算和存储成本。</li>\n  <li><strong>不影响推理速度</strong>：在推理阶段，将低秩矩阵的更新合并到原始权重矩阵中，不会增加额外的推理时间。</li>\n</ul>\n<h3>P - tuning（Prompt Tuning）</h3>\n<h4>原理</h4>\n<p>P - tuning是一种基于提示学习的微调方法，其核心是通过学习连续的提示向量来引导预训练模型完成特定任务。</p>\n<ul>\n  <li><strong>提示向量</strong>：在输入文本前添加一组可训练的连续向量作为提示，这些提示向量可以看作是一种软提示，与输入文本一起输入到预训练模型中。模型在微调过程中学习这些提示向量的值，使得模型能够根据提示更好地完成特定任务。</li>\n  <li><strong>任务适配</strong>：通过调整提示向量，模型可以在不改变预训练模型参数的情况下，适应不同的任务。例如，在文本分类任务中，合适的提示向量可以引导模型将输入文本分类到正确的类别中。</li>\n</ul>\n<h4>优势</h4>\n<ul>\n  <li><strong>参数高效</strong>：只需要训练提示向量，而不需要更新预训练模型的大量参数，减少了计算和存储开销。</li>\n  <li><strong>通用性强</strong>：可以在不同的预训练模型上使用，并且可以通过调整提示向量快速适应不同的任务。</li>\n</ul>",
    "type": 6,
    "level": 2,
    "freq": 0.002908184,
    "analysis": "<h3>1. 题目核心</h3>\n<ul>\n  <li><strong>问题</strong>：阐述大模型微调技术原理，如LoRA、P - tuning。</li>\n  <li><strong>考察点</strong>：\n    <ul>\n      <li>对大模型微调概念的理解。</li>\n      <li>LoRA和P - tuning技术的具体原理。</li>\n      <li>这两种技术在大模型微调中的作用和优势。</li>\n    </ul>\n  </li>\n</ul>\n<h3>2. 背景知识</h3>\n<h4>（1）大模型微调的概念</h4>\n<p>大模型通常在大规模通用数据上进行预训练，具备广泛的语言知识和能力。但在特定任务上，直接使用预训练模型效果可能不佳。微调就是在预训练模型的基础上，使用特定任务的数据对模型进行进一步训练，使模型适应特定任务。传统的全量参数微调需要更新模型的所有参数，计算资源和存储需求大。</p>\n<h3>3. 解析</h3>\n<h4>（1）LoRA（Low - Rank Adaptation）技术原理</h4>\n<ul>\n  <li><strong>核心思想</strong>：LoRA不直接调整预训练模型的原始参数，而是在模型的某些层（如注意力层）引入可训练的低秩矩阵，通过更新这些低秩矩阵来实现模型对特定任务的适配。</li>\n  <li><strong>具体实现</strong>：假设预训练模型的权重矩阵为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W_0</annotation>\n        </semantics>\n      </math></span>，在微调时，将其更新为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>W</mi>\n            <mo>=</mo>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n            <mo>+</mo>\n            <mi mathvariant=\"normal\">Δ</mi>\n            <mi>W</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W = W_0+\\Delta W</annotation>\n        </semantics>\n      </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi mathvariant=\"normal\">Δ</mi>\n            <mi>W</mi>\n            <mo>=</mo>\n            <mi>B</mi>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">\\Delta W = BA</annotation>\n        </semantics>\n      </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">B</annotation>\n        </semantics>\n      </math></span> 是形状为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mo stretchy=\"false\">(</mo>\n            <mi>d</mi>\n            <mo separator=\"true\">,</mo>\n            <mi>r</mi>\n            <mo stretchy=\"false\">)</mo>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">(d, r)</annotation>\n        </semantics>\n      </math></span> 的矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">A</annotation>\n        </semantics>\n      </math></span> 是形状为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mo stretchy=\"false\">(</mo>\n            <mi>r</mi>\n            <mo separator=\"true\">,</mo>\n            <mi>k</mi>\n            <mo stretchy=\"false\">)</mo>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">(r, k)</annotation>\n        </semantics>\n      </math></span> 的矩阵，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>r</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">r</annotation>\n        </semantics>\n      </math></span> 远小于 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>d</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">d</annotation>\n        </semantics>\n      </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>k</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">k</annotation>\n        </semantics>\n      </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>r</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">r</annotation>\n        </semantics>\n      </math></span> 就是低秩矩阵的秩。在训练过程中，只更新 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>A</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">A</annotation>\n        </semantics>\n      </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <mi>B</mi>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">B</annotation>\n        </semantics>\n      </math></span> 矩阵，而 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n        <semantics>\n          <mrow>\n            <msub>\n              <mi>W</mi>\n              <mn>0</mn>\n            </msub>\n          </mrow>\n          <annotation encoding=\"application/x-tex\">W_0</annotation>\n        </semantics>\n      </math></span> 保持不变。这样可以大大减少可训练参数的数量。</li>\n  <li><strong>优势</strong>：减少了微调所需的计算资源和存储需求，同时可以在不改变预训练模型权重的情况下快速适应新任务，并且可以与预训练模型的权重进行高效合并，在推理时不增加额外的计算开销。</li>\n</ul>\n<h4>（2）P - tuning（Prompt - tuning）技术原理</h4>\n<ul>\n  <li><strong>核心思想</strong>：P - tuning通过在输入中添加可训练的连续提示（prompt）来引导预训练模型完成特定任务，而不是直接调整模型的主体参数。</li>\n  <li><strong>具体实现</strong>：在输入文本前添加一段可训练的向量序列作为提示，这些提示向量在微调过程中不断更新。模型在处理输入时，将这些提示向量和原始输入一起进行处理，从而学习到特定任务的模式。例如，在文本分类任务中，通过调整提示向量，让模型更好地理解如何对文本进行分类。</li>\n  <li><strong>优势</strong>：避免了对大规模预训练模型参数的更新，减少了计算量和存储需求。同时，提示向量可以灵活地适应不同的任务，提高了模型的通用性和灵活性。</li>\n</ul>\n<h3>4. 示例代码（以Hugging Face库为例简单示意LoRA）</h3>\n<pre><code class=\"language-python\">from peft import LoraConfig, get_peft_model\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\n\n# 加载预训练模型和分词器\nmodel_name = \"bert-base-uncased\"\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# 配置LoRA\nconfig = LoraConfig(\n    r=8,  # 低秩矩阵的秩\n    lora_alpha=16,\n    target_modules=[\"query\", \"key\", \"value\"],  # 应用LoRA的模块\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=\"SEQ_CLS\"\n)\n\n# 应用LoRA到模型\nmodel = get_peft_model(model, config)\n\n# 后续可以进行微调训练\n</code></pre>\n<h3>5. 常见误区</h3>\n<h4>（1）认为所有微调技术都需要更新全量参数</h4>\n<ul>\n  <li>误区：认为微调大模型就必须更新模型的所有参数。</li>\n  <li>纠正：像LoRA和P - tuning这类技术，通过引入额外的可训练组件或提示，避免了对全量参数的更新，减少了计算和存储成本。</li>\n</ul>\n<h4>（2）混淆LoRA和P - tuning的原理</h4>\n<ul>\n  <li>误区：不能清晰区分LoRA通过低秩矩阵更新和P - tuning通过提示向量引导的不同原理。</li>\n  <li>纠正：明确LoRA是在模型层引入低秩矩阵更新，而P - tuning是在输入中添加可训练提示。</li>\n</ul>\n<h4>（3）忽视技术的适用场景</h4>\n<ul>\n  <li>误区：不考虑任务特点和资源限制，随意选择微调技术。</li>\n  <li>纠正：LoRA适用于需要对模型层参数进行一定调整的场景，P - tuning更适合通过输入提示就能引导模型完成任务的场景。</li>\n</ul>\n<h3>6. 总结回答</h3>\n<p>大模型微调是在预训练模型基础上使用特定任务数据进一步训练以适应特定任务。LoRA和P - tuning是两种高效的微调技术。</p>\n<p>LoRA的原理是在模型的某些层引入可训练的低秩矩阵，将预训练模型权重 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 更新为 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>W</mi>\n          <mo>=</mo>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n          <mo>+</mo>\n          <mi mathvariant=\"normal\">Δ</mi>\n          <mi>W</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W = W_0+\\Delta W</annotation>\n      </semantics>\n    </math></span>，其中 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi mathvariant=\"normal\">Δ</mi>\n          <mi>W</mi>\n          <mo>=</mo>\n          <mi>B</mi>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">\\Delta W = BA</annotation>\n      </semantics>\n    </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 是低秩矩阵。训练时只更新 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>A</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">A</annotation>\n      </semantics>\n    </math></span> 和 <span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <mi>B</mi>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">B</annotation>\n      </semantics>\n    </math></span>，<span class=\"katex\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\">\n      <semantics>\n        <mrow>\n          <msub>\n            <mi>W</mi>\n            <mn>0</mn>\n          </msub>\n        </mrow>\n        <annotation encoding=\"application/x-tex\">W_0</annotation>\n      </semantics>\n    </math></span> 不变，减少了可训练参数数量，降低计算和存储需求，且推理时不增加额外开销。</p>\n<p>P - tuning则是在输入中添加可训练的连续提示向量，模型将提示向量和原始输入一起处理，通过更新提示向量引导模型完成特定任务，避免了对模型主体参数的更新，提高了模型通用性和灵活性。</p>\n<p>不过，在选择微调技术时，要考虑任务特点和资源限制，LoRA适合对模型层参数调整的场景，P - tuning适合通过输入提示引导任务的场景。</p>",
    "more_ask": "<ol>\n  <li>LoRA在不同规模模型上的微调效果有何差异？提示：考虑小、中、大规模模型的参数数量、计算资源需求等因素对LoRA微调效果的影响。</li>\n  <li>P - tuning在处理长文本任务时会遇到什么挑战，如何解决？提示：从长文本的上下文理解、计算复杂度等方面思考挑战及应对策略。</li>\n  <li>除了LoRA和P - tuning，还有哪些新兴的大模型微调技术，它们的优势是什么？提示：关注近期学术研究和行业动态中出现的新微调方法。</li>\n  <li>如何评估LoRA微调后模型的性能提升？提示：可以从准确率、召回率、F1值等指标，以及与未微调模型对比等角度考虑。</li>\n  <li>P - tuning中软提示的设计有哪些关键要点？提示：思考软提示的长度、初始化方式、与模型交互等方面。</li>\n  <li>LoRA微调时，如何选择合适的秩（rank）参数？提示：结合模型的复杂度、数据集大小和计算资源等因素。</li>\n  <li>在多模态大模型中应用P - tuning有什么特殊之处？提示：考虑多模态数据（如图像、文本等）的特点和融合方式。</li>\n  <li>当数据集规模较小时，LoRA和P - tuning哪种方法更合适，为什么？提示：分析两种方法在小数据集上的泛化能力、参数更新方式等。</li>\n  <li>如何将LoRA和P - tuning结合使用，有什么潜在优势？提示：思考两种方法的互补性，如参数高效性和提示学习的结合。</li>\n  <li>大模型微调技术对模型的可解释性有什么影响？提示：从微调后模型的决策过程、参数变化等方面分析对可解释性的作用。</li>\n</ol>",
    "mindmap": "mindmap\n  root((大模型微调概述))\n    大模型微调定义\n      基于预训练大模型针对特定任务或领域数据进一步训练\n      提升特定场景下模型性能\n    微调类型\n      传统全量参数微调\n        需更新所有参数\n        计算和存储需求大\n      高效微调技术\n        LoRA\n          原理\n            低秩分解\n            权重更新\n          优势\n            减少训练参数\n            不影响推理速度\n        P - tuning\n          原理\n            提示向量\n            任务适配\n          优势\n            参数高效\n            通用性强",
    "keynote": "大模型微调：基于预训练模型针对特定任务或领域数据训练，提升特定场景性能\n传统全量参数微调：更新所有参数，计算和存储需求大\nLoRA：核心是低秩分解近似表示参数更新，减少训练参数，不影响推理速度\nP - tuning：基于提示学习，学习连续提示向量引导模型，参数高效、通用性强",
    "group_id": 108,
    "kps": [
      "深度学习",
      "大模型"
    ],
    "years": [
      2025,
      2024,
      2023
    ],
    "corps": [
      "快商通",
      "拼多多",
      "饿了么",
      "腾讯",
      "美团",
      "百度"
    ]
  }
}